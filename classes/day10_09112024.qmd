---
title: "Day 10 - 09/11/2024"
format: html
editor: visual
---

## Statistical Inference  

```{r message=FALSE, warning=FALSE}
library(tidyverse)
url <- 
"https://raw.githubusercontent.com/jlacasa/stat705_fall2024/main/classes/data/lotus_part1.csv"
data <- read.csv(url)
 
data %>% 
  ggplot(aes(species, agb_g))+
  geom_boxplot()+
  labs(x = "Species", 
       y = "Aboveground biomass (g)")+
  theme_classic()+
  theme(aspect.ratio = 1)
```

Let's take a simple statistical model:  

The aboveground biomass from the $i$th observation, $y_i$, can be described as 
$$y_i \sim N(\mu_i , \sigma^2),$$

$$\mu_i = \beta_1 x_{1i} + \beta_2 x_{2i} + \beta_3 x_{3i},$$
$$x_{1 i} \left \{
  \begin{aligned}
    & 1 && \text{if species A} \\
    & 0 && \text{else}
  \end{aligned} \right.,$$
$$x_{2 i} \left \{
  \begin{aligned}
    & 1 && \text{if species C} \\
    & 0 && \text{else}
  \end{aligned} \right.,$$
$$x_{3 i} \left \{
  \begin{aligned}
    & 1 && \text{if species D} \\
    & 0 && \text{else}
  \end{aligned} \right.,$$

for $i =1, 2, ..., n$, where $n$ is the total number of observations, $\mu_i$ is the mean of the $i$th observation, $x_{1i}$, $x_{2i}$, and $x_{3i}$ are indicator variables that identify the species as A, C, or D, and thus $\beta_1$, $\beta_2$, and $\beta_3$ are the means of genotypes A, C, and D, respectively, and $\sigma^2$ is the variance of the data.  

```{r}
m <- lm(agb_g ~ 0 + species , data = data)
beta_hat <- coef(m)

m
```


### 95% Confidence intervals  

```{r}
confint(m)
```

### T-test  

```{r}
X <- model.matrix(m)
sigma_hat <- summary(m)$sigma
unscaled_covariance <- solve(t(X)%*%X)
(se <- sqrt(diag(unscaled_covariance))*sigma_hat)
dfe <- (nrow(data)-3)
```

The t statistic 
$$T = \frac{\hat\theta}{s.e.(\hat\theta)}$$

is used to compute the p value in hypothesis tests. The p value is the probability of observing the t statistic under the conditions of the null hypothesis. In this formula, $\hat\theta$ is an estimator of an operation of the parameters, e.g., $\theta = \beta_1 - 0$ or $\theta = \beta_1-\beta_2$.

The t distribution is similar to a normal distribution, but with heavier tails.  

```{r }
x <- seq(-5, 5, by = .1)
dt <- dt(x, dfe)
tc <- qt(.975, dfe)

data.frame(x, dt) %>% 
  ggplot(aes(x, dt))+
  geom_ribbon(aes(ymin = 0, ymax = dt), 
              data = . %>% filter(x < -tc))+
  geom_ribbon(aes(ymin = 0, ymax = dt), 
              data = . %>% filter(x > tc))+
  labs(y = "[t]", 
       x= "t score")+
  geom_line()+
  theme(aspect.ratio = 1)+
  coord_cartesian(expand = F)+
  theme_classic()
```


In the `summary` output, we have $\theta = \beta_j-0$, i.e., we are testing if a given $\beta_j$ is different to zero.  

```{r}
t_A <- (beta_hat[1] - 0)/se[1]
t_A
t_C <- (beta_hat[2] - 0)/se[2]
t_C
t_D <- (beta_hat[3] - 0)/se[3]
t_D
```

```{r}
dt(t_A, dfe)
dt(t_C, dfe)
dt(t_D, dfe)
```


### The General linear F-test  

Compare the "full" model (our proposed model) to the "reduced" (intercept only) model.  

```{r message=FALSE, warning=FALSE}
library(ggpubr)
data2 <- read.csv("https://raw.githubusercontent.com/jlacasa/stat705_fall2024/main/classes/data/lotus_hw1.csv")
m2_full <- lm(stm.length_cm ~ doy , data = data2)
m2_red <- lm(stm.length_cm ~ 1 , data = data2)

ggarrange(data2 %>% 
            ggplot(aes(doy, stm.length_cm))+
            geom_point()+
            stat_function(fun = function(x){
              coef(m2_full)[1]+x*coef(m2_full)[2]
            })+
            labs(x = "Day of the Year", 
                 y = "Stem length (cm)")+
            theme_classic()+
            theme(aspect.ratio = 1),
          data2 %>% 
            ggplot(aes(doy, stm.length_cm))+
            geom_point()+
            stat_function(fun = function(x){
              coef(m2_red)[1]
            })+
            labs(x = "Day of the Year", 
                 y = "Stem length (cm)")+
            theme_classic()+
            theme(aspect.ratio = 1),
          ncol = 2)
```


```{r message=FALSE, warning=FALSE}
m_full <- lm(agb_g ~ species , data = data)
m_red <- lm(agb_g ~ 1 , data = data)
ggarrange(data %>% 
            mutate(pred = predict(m_full, type = "response")) %>% 
            ggplot(aes(species, agb_g))+
            geom_point()+
            geom_point(aes(y = pred), size =4, shape = 21,  fill = "magenta")+
            labs(x = "Species", 
                 y = "Aboveground biomass (g)")+
            theme_classic()+
            theme(aspect.ratio = 1),
          data %>% 
            mutate(pred = predict(m_red, type = "response")) %>% 
            ggplot(aes(species, agb_g))+
            geom_point()+
            geom_hline(aes(yintercept = pred), size =2, color = "magenta")+
            labs(x = "Species", 
                 y = "Aboveground biomass (g)")+
            theme_classic()+
            theme(aspect.ratio = 1),
          ncol = 2)
```

```{r}
SSE_full <- sum(m_full$residuals^2)
SSE_red <- sum(m_red$residuals^2)

df_full <- m_full$df.residual
df_red <- m_red$df.residual

n <- nrow(data)
F_star <- ((SSE_red-SSE_full)/(df_red-df_full)) / (SSE_full/df_full)
(p_value <- df(F_star, df1 = 1, df2 = dfe))

summary(m_full)
```

### Summary  

Now we know where (almost) everything in the `summary` output comes from!   

```{r eval=FALSE}
summary(m)
```

![](misc_plots/summary_comments.png)



### More on t tests   

Recall that the t statistic $T = \frac{\hat\theta}{s.e.(\hat\theta)}$ is used to compute the p value in hypothesis tests. We tested $\beta_1 = 0$ before, but what about $\beta_1 = \beta_2$? In other words, we want to test if the difference between $\beta_1$ and $\beta_2$ is different to zero.  
In this case, $s.e.(\hat\beta_1 - \hat\beta_2) = \sqrt{s.e.(\hat\beta_1)^2+ s.e.(\hat\beta_2)^2 -2\text{cov}(\hat\beta_1, \hat\beta_2)}$.

```{r}
c_1 <- (beta_hat[1]-beta_hat[2])/sqrt(se[1]^2 + se[2]^2)
dt(c_1, dfe)
c_2 <- (beta_hat[1]-beta_hat[3])/sqrt(se[1]^2 + se[3]^2)
dt(c_2, dfe)
c_3 <- (beta_hat[2]-beta_hat[3])/sqrt(se[2]^2 + se[3]^2)
dt(c_3, dfe)
```

#### An interpretation of 95% CI using t-tests   

Recall the 95% CI of $\hat\beta_1$:  

```{r}
confint(m)
```

```{r}
dt((beta_hat[1] - 2.67)/( se[1]/sqrt(1)), dfe)
dt((beta_hat[1] - 2.68)/( se[1]/sqrt(1)), dfe)
dt((beta_hat[1] - 2.7)/( se[1]/sqrt(1)), dfe)
```

```{r}
comp <- seq(2, 3, by = .01)
p.save <- numeric(length(comp))

for (i in 1:length(comp)) {
  p.save[i] <- dt((beta_hat[1] - comp[i])/( se[1]/sqrt(1)), dfe)
}

data.frame(comp, p.save) %>% 
  ggplot(aes(comp, p.save))+
  geom_line()+
  labs(y = "p value", 
       x = "comparing the mean with ...")+
  geom_hline(yintercept = .05, linetype =2, color = 'red')+
  geom_vline(xintercept = confint(m)[1], linetype= 2)+
  theme_bw()
```

## Multiple comparisons  

```{r message=FALSE, warning=FALSE}
library(emmeans)
library(multcomp)
(lsmeans <- emmeans(m, ~species))
cld(lsmeans, 
    adjust = 'sidak',
    Letters = letters)
```


## But why do we care if something is significant?  

- What would you say for an effect with p = 0.049 and one with 0.051? Are both significant?   
- See [this paper](https://stat.columbia.edu/~gelman/research/published/signif4.pdf).  
- A few things to have in mind when evaluating effects:   
  - is this difference meaningful?  
  - what is the noise in these estimations?  
- Why are we learning about p-values then?  


